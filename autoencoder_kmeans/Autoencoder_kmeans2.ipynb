{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "# import cv2\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "#%% import data\n",
        "root = 'content/drive/Shareddrives/EC523 Project/Dataset1_benchmark'\n",
        "# 'projectnb/dl523/students/izhou/'\n",
        "\n",
        "def read_tiff(path):\n",
        "    img = Image.open(path)\n",
        "    images = []\n",
        "    for i in range(img.n_frames):\n",
        "        img.seek(i)\n",
        "        images.append(np.array(img))\n",
        "    return np.array(images)\n",
        "\n",
        "images1 = read_tiff('/content/drive/Shareddrives/EC523 Project/Dataset1_benchmark/Gene1.tif')\n",
        "dim = images1.shape\n",
        "images_allGenes = np.zeros((15,dim[0],dim[1],dim[2]))\n",
        "images_allGenes[0,:,:,:] = images1"
      ],
      "metadata": {
        "id": "DVQy-eMC4bRJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OhJ8JSBc4Qzj"
      },
      "outputs": [],
      "source": [
        "#!/usr/bin/env python3\n",
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Created on Mon Apr  3 10:38:25 2023\n",
        "\n",
        "@author: IreneZhou\n",
        "\"\"\"\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "# import cv2\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "for i in range(2,16):\n",
        "  path = '/content/drive/Shareddrives/EC523 Project/Dataset1_benchmark/Gene' + str(i) + '.tif'\n",
        "  image = read_tiff(path)\n",
        "  images_allGenes[i-1,:,:,:] = image\n",
        "\n",
        "\n",
        "\n",
        "#%%  basic k-means\n",
        "# images_allGenes: [gene, z, x, y]\n",
        "#                  (15, 25, 2006, 2005)\n",
        "\n",
        "# z1 = images_allGenes[:,0,:,:]\n",
        "\n",
        "\n",
        "# kmeans = KMeans(n_clusters=48)\n",
        "# data = list()\n",
        "\n",
        "# for i in range(z1.shape[1]):\n",
        "#     for j in range(z1.shape[2]):\n",
        "#         data.append(z1[:,i,j])\n",
        "        \n",
        "        \n",
        "# kmeans_result = kmeans.fit(data)\n",
        "\n",
        "# labels = kmeans_result.labels_\n",
        "\n",
        "# z1_labeled = labels.reshape((z1.shape[1],z1.shape[2]))\n",
        "\n",
        "# from matplotlib import pyplot as plt\n",
        "# plt.imshow(z1_labeled, interpolation='nearest')\n",
        "# plt.savefig('./Dataset1_benchmark/simple_kmeans/z1_simpleKMeans_48.jpg', dpi = 300)\n",
        "\n",
        "# plt.show()\n",
        "\n",
        "#%% autoencoder\n",
        "# images_allGenes: [gene, z, x, y]\n",
        "#                  (15, 25, 2006, 2005)\n",
        "z1 = images_allGenes[:,0,:,:] # 15,2006,2005\n",
        "transform = transforms.ToTensor()\n",
        "\n",
        "z1 = transform(z1)\n",
        "z1 = z1.permute(1,2,0)\n",
        "z1 = torch.reshape(z1,(15, 2006*2005))\n",
        "\n",
        "# normalize to [0,1]\n",
        "z1 = z1/z1.max()\n",
        "\n",
        "\n",
        "#%% model\n",
        "class Autoencoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # 2006*2005 (batch), 15\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Linear(2006*2005, 1024),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(1024, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512,256),     \n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256,128)\n",
        "        )\n",
        "        \n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(128,256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256,512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512,1024),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(1024,2006*2005),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "        \n",
        "    \n",
        "    def forward(self, x):\n",
        "        encoded = self.encoder(x)\n",
        "        decoded = self.decoder(encoded)\n",
        "        return encoded, decoded\n",
        "\n",
        "#%% train\n",
        "model = Autoencoder()\n",
        "model.double()\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr = 1e-4, momentum = 0.9)\n",
        "\n",
        "epochs = 10\n",
        "encoded_list = list()\n",
        "decoded_list = list()\n",
        "loss_track = list()\n",
        "print('Start training')\n",
        "for epoch in range(epochs):\n",
        "    for batch in range(len(z1)):\n",
        "        vec = z1[batch, :]\n",
        "        # print(vec.shape)\n",
        "        encoded, decoded = model(vec)\n",
        "        loss = criterion(decoded, vec)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if epoch == epochs - 1:\n",
        "            encoded_list.append(encoded.detach().numpy())   # 15 x 4000000\n",
        "            decoded_list.append(decoded.detach().numpy())\n",
        "    loss_track.append(loss.item())    \n",
        "\n",
        "#%% save outputs\n",
        "import pickle\n",
        "\n",
        "# with open('encoded','wb') as fp:\n",
        "#     pickle.dump(encoded_list, fp)\n",
        "\n",
        "with open('decoded','wb') as fp:\n",
        "    pickle.dump(decoded_list, fp)\n",
        "    \n",
        "    \n",
        "# with open('encoded','rb') as fp:\n",
        "#     encoded_list = pickle.load(fp)\n",
        "# with open('decoded','rb') as fp:\n",
        "#     decoded_list = pickle.load(fp)\n",
        "\n",
        "\n",
        "\n",
        "#%% reshape\n",
        "decoded_list = np.array(decoded_list)\n",
        "decoded_vec = list()\n",
        "for i in range(decoded_list.shape[1]):\n",
        "    decoded_vec.append(decoded_list[:,i])\n",
        "\n",
        "\n",
        "#%% k-means, decoded\n",
        "kmeans = KMeans(n_clusters=48) \n",
        "kmeans_decoded = kmeans.fit(decoded_vec)\n",
        "#%%\n",
        "labels_decoded = kmeans_decoded.labels_\n",
        "# print(labels_encoded.shape)\n",
        "# print(labels_decoded.shape)\n",
        "\n",
        "labels_decoded = labels_decoded.reshape((images_allGenes.shape[2],images_allGenes.shape[3]))\n",
        "\n",
        "plt.imshow(labels_decoded, interpolation='nearest')\n",
        "plt.savefig('./z1_decoded_48.jpg', dpi = 300)\n",
        "plt.show()\n",
        "\n",
        "\n",
        "plt.plot(loss_track)\n",
        "plt.savefig('./z1_loss_plot.jpg',dpi = 300)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "# Define path to the dataset\n",
        "root = 'content/drive/Shareddrives/EC523 Project/Dataset1_benchmark'\n"
      ],
      "metadata": {
        "id": "Ch_ggonZrjvB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OhJ8JSBc4Qzj"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "# Define path to the dataset\n",
        "root = 'content/drive/Shareddrives/EC523 Project/Dataset1_benchmark'\n",
        "\n",
        "# Function to read tiff images\n",
        "def read_tiff(path):\n",
        "    img = Image.open(path)\n",
        "    images = []\n",
        "    for i in range(img.n_frames):\n",
        "        img.seek(i)\n",
        "        images.append(np.array(img))\n",
        "    return np.array(images)\n",
        "\n",
        "# Load and store all images\n",
        "images_allGenes = np.zeros((15, 25, 2006, 2005))\n",
        "for i in range(1, 16):\n",
        "    path = f'{root}/Gene{i}.tif'\n",
        "    image = read_tiff(path)\n",
        "    images_allGenes[i-1, :, :, :] = image\n",
        "\n",
        "# Preprocess images\n",
        "z1 = images_allGenes[:, 0, :, :]\n",
        "transform = transforms.ToTensor()\n",
        "z1 = transform(z1)\n",
        "z1 = z1.permute(1, 2, 0)\n",
        "z1 = torch.reshape(z1, (15, 2006 * 2005))\n",
        "z1 = z1 / z1.max()\n",
        "\n",
        "# Define autoencoder model\n",
        "class Autoencoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Linear(2006 * 2005, 1024),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(1024, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, 128)\n",
        "        )\n",
        "        \n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(128, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 1024),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(1024, 2006 * 2005),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "        \n",
        "    def forward(self, x):\n",
        "        encoded = self.encoder(x)\n",
        "        decoded = self.decoder(encoded)\n",
        "        return encoded, decoded\n",
        "\n",
        "# Train autoencoder\n",
        "model = Autoencoder()\n",
        "model.double()\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=1e-4, momentum=0.9)\n",
        "\n",
        "epochs = 10\n",
        "encoded_list = []\n",
        "decoded_list = []\n",
        "loss_track = []\n",
        "\n",
        "print('Start training')\n",
        "for epoch in range(epochs):\n",
        "    for batch in range(len(z1)):\n",
        "        vec = z1[batch, :]\n",
        "        encoded, decoded = model(vec)\n",
        "        loss = criterion(decoded, vec)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if epoch == epochs - 1:\n",
        "            encoded_list.append(encoded.detach().numpy())\n",
        "            decoded_list.append(decoded.detach().numpy())\n",
        "    loss_track.append(loss.item())\n",
        "\n",
        "# Save outputs\n",
        "import pickle\n",
        "\n",
        "with open('decoded', 'wb') as fp:\n",
        "    pickle.dump(decoded_list, fp)\n",
        "\n",
        "# Reshape decoded output\n",
        "decoded_list = np.array(decoded_list)\n",
        "decoded_vec = [decoded_list[:, i] for i in range(decoded_list.shape[1])]\n",
        "\n",
        "# Perform k-means clustering on the decoded output\n",
        "kmeans = KMeans(n_clusters=48)\n",
        "kmeans_decoded = kmeans.fit(decoded_vec)\n",
        "labels_decoded = kmeans_decoded.labels_\n",
        "labels_decoded = labels_decoded.reshape((images_allGenes.shape[2],\n",
        "images_allGenes.shape[3]))\n",
        "\n",
        "# Visualize the clustered output\n",
        "plt.imshow(labels_decoded, interpolation='nearest')\n",
        "plt.savefig('./z1_decoded_48.jpg', dpi=300)\n",
        "plt.show()\n",
        "\n",
        "# Plot the loss curve\n",
        "plt.plot(loss_track)\n",
        "plt.savefig('./z1_loss_plot.jpg', dpi=300)\n"
      ]
    }
  ]
}